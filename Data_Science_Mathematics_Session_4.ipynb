{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Mathematics\n",
    "# K-Means Clustering\n",
    "# In-Class Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze our data set using the K-means module of Python.  First, import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import our dataset as a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array([[8,22,62],\n",
    "[15,51,85],\n",
    "[9,44,121],\n",
    "[8,51,136],\n",
    "[8,20,93],\n",
    "[15,64,124],\n",
    "[14,56,101],\n",
    "[5,10,80],\n",
    "[5,18,73],\n",
    "[9,26,79]])\n",
    "\n",
    "labels = [1,0,0,0,1,0,0,1,1,1]\n",
    "\n",
    "centroids=[[10,20,80],[10,50,110]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcdist(data,centroids):\n",
    "    dist1 = []\n",
    "    dist2 = []\n",
    "    for pt in data: \n",
    "        pt1dist = np.sqrt((pt[0]-centroids[0][0])**2+(pt[1]-centroids[0][1])**2+(pt[2]-centroids[0][2])**2)\n",
    "        pt2dist = np.sqrt((pt[0]-centroids[1][0])**2+(pt[1]-centroids[1][1])**2+(pt[2]-centroids[1][2])**2)\n",
    "        dist1.append(pt1dist)\n",
    "        dist2.append(pt2dist)\n",
    "    return dist1, dist2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(data,dist1,dist2):\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    for idx in range(len(data)):\n",
    "        if dist1[idx] < dist2[idx]:\n",
    "            cluster1.append(list(data[idx]))\n",
    "        else: cluster2.append(list(data[idx]))\n",
    "            \n",
    "    return cluster1, cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calccentroids(cluster):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    z = 0\n",
    "    for pt in cluster:\n",
    "        x += pt[0]\n",
    "        y += pt[1]\n",
    "        z += pt[2]\n",
    "    return [x/len(cluster),y/len(cluster),z/len(cluster)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 20, 80], [10, 50, 110]]\n",
      "[[7.0, 19.2, 77.4], [12.2, 53.2, 113.4]]\n",
      "[[7.0, 19.2, 77.4], [12.2, 53.2, 113.4]]\n",
      "[[7.0, 19.2, 77.4], [12.2, 53.2, 113.4]]\n",
      "[[7.0, 19.2, 77.4], [12.2, 53.2, 113.4]]\n"
     ]
    }
   ],
   "source": [
    "#Write the algorithms for \n",
    "for i in range(5):\n",
    "    print(centroids)\n",
    "    dist1,dist2 = calcdist(data,centroids)\n",
    "    cluster1,cluster2 = cluster(data,dist1,dist2)\n",
    "    centroids[0] = calccentroids(cluster1)\n",
    "    centroids[1] = calccentroids(cluster2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 22, 62], [8, 20, 93], [5, 10, 80], [5, 18, 73], [9, 26, 79]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for pt in data:\n",
    "    if list(pt) in cluster1:\n",
    "        output.append(1)\n",
    "    else: output.append(0)\n",
    "    \n",
    "print(output)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate our k-means object, trained on our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the \"labels\" method to get our data labels.  Each different integer represents a different cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the lables make sense based on our input data?  Go back to the in-class activity and see if the labels ar the same.  Note that this algorithm may choose a different label convention (i.e., not 1=Military and 0=Non-Military, like in our example).  What we are interested in is the correct pattern in the label sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find our centroids.  Do they match what you calculated where you wrote the code above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.5       ,  53.75      , 120.5       ],\n",
       "       [  8.33333333,  24.5       ,  78.66666667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now save your output.  Go to File -> Print Preview and save your final output as a PDF.  Turn in to your Instructor, along with any additional sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How well did your algorithm cluster military personnel versus non-military personnel? Construct a confusion matrix, and calculate the Matthews's Correlation Coefficient (write the code vs. using NumPy - feel free to check with NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# The Confusion Matrix would look something like this:\n",
    "# TP: 5 / FP: 0 / TN: 5 / FN: 0\n",
    "# Calculating the MCC = (TP*TN-FP*FN)/((TP+FP)*(TP+FN)*(TN+FP)(TN+FN))**1/2\n",
    "\n",
    "Numerator = 5*5-0*0\n",
    "Denominator = np.sqrt((5+0)*(5+0)*(5+0)*(5+0))\n",
    "MCC = (Numerator/Denominator)\n",
    "print(MCC)\n",
    "\n",
    "#A result of 1.0 means they are perfectly correlated in a positive direction (algorithm did as well as the original data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###You selected three features to use in this computation because you determined that they are the three most correlated features with \"military\" status. While adding additional features up to a certain point will enhance clustering model accuracy, adding too many features diminishes accuracy. Explain why this is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the \"curse of dimensionality\" basically says that the more dimensions you add, the greater the chance of reaching a place (n-dimensional space) where all points are far from a centroid because of the number of dimensions -- the model that best explains this is the volume of an n-dimensional sphere inside of an n-dimensional cube - as the number of dimensions increases and the volume goes with it, the corners of the cube (data points) become equally far from the center (centroids), making the centroids of little to no value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
